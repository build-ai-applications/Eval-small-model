{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ae3adb",
   "metadata": {},
   "source": [
    "# Modules testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3b36a-262e-4105-ac8c-3471065d7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sglang as sgl\n",
    "import asyncio\n",
    "\n",
    "llm = sgl.Engine(model_path=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "# llm = sgl.Engine(model_path=\"stabilityai/stablelm-2-1_6b\")\n",
    "# llm = sgl.Engine(model_path=\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")\n",
    "# llm = sgl.Engine(model_path=\"meta-llama/Llama-3.2-3B-Tnstruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17214f47",
   "metadata": {},
   "source": [
    "## Sample input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd29036-162d-4c5c-b4d7-983573d9b8fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing synchronous streaming generation ===\n",
      "\n",
      "Prompt: Write a one poem on soldier for me.\n",
      " The poem should be about the importance of being a soldier, the battle, the battles, the victory, and the soldiers. It should be 4 lines per stanza, 8 stanzas, and 16 lines total. The poem should be in iambic tetrameter. Also, the poem should be in free verse, not rhyming. I need to include the important details about the battles, the victory, the soldiers, and the battle itself. The poem should be about the soldiers, not the battles or the victory, but the soldiers themselves. The soldiers are the ones who fight, the ones who fight\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Write a one poem on soldier for me.\",\n",
    "]\n",
    "sampling_params = {\"temperature\": 0.5, \"top_p\": 0.95}\n",
    "\n",
    "print(\"\\n=== Testing synchronous streaming generation ===\")\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"Generated text: \", end=\"\")\n",
    "\n",
    "    response = llm.generate(prompt, sampling_params, stream=False)\n",
    "    print(response['text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa4314",
   "metadata": {},
   "source": [
    "## Some repositry of models may need sign in To use them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bd24aa-82f3-440a-84cf-39f8bce8cdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quoppo/sglang1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from huggingface_hub import login\n",
    "\n",
    "# login(\"YourHFKey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed4b2f5",
   "metadata": {},
   "source": [
    "### Evaluation generation with sglang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca24868e-398e-4b24-a2fe-bb3e2aac1071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quoppo/sglang1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-04 14:14:26,884\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.54s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.54s/it]\n",
      "\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Write a short poem about a soldier.\n",
      "Processed: Summarize the plot of 'To Kill a Mockingbird' in a few sentences.\n",
      "Processed: Explain the process of photosynthesis in simple terms.\n",
      "Processed: Describe the importance of cybersecurity in modern society.\n",
      "Processed: What are the benefits of regular exercise?\n",
      "Processed: Outline the major causes of climate change.\n",
      "Processed: Write a brief story about an astronaut on Mars.\n",
      "Processed: Compare and contrast two different types of renewable energy.\n",
      "Processed: Describe how a computer works in layman’s terms.\n",
      "Processed: What is the significance of the scientific method?\n",
      "Processed: Explain the benefits of meditation for stress relief.\n",
      "Processed: Write a creative short story involving a mysterious door.\n",
      "Processed: Discuss the impact of social media on communication.\n",
      "Processed: Explain how the stock market works in simple language.\n",
      "Processed: Describe the importance of voting in a democracy.\n",
      "Processed: Write a motivational message for someone facing challenges.\n",
      "Processed: Summarize the rules of chess.\n",
      "Processed: Explain what makes a good leader.\n",
      "Processed: Outline the steps required to start a small business.\n",
      "Processed: Discuss the ethical considerations of artificial intelligence.\n",
      "Generation complete. Responses stored in generation_responses.json\n"
     ]
    }
   ],
   "source": [
    "import sglang as sgl\n",
    "import json\n",
    "# gen = \"Qwen/Qwen2.5-Coder-1.5B-Instruct\"\n",
    "# gen = \"tiiuae/Falcon3-3B-Instruct\"\n",
    "# gen = \"Qwen/Qwen2.5-Math-1.5B-Instruct\"\n",
    "# gen = \"BSC-LT/salamandra-2b-instruct\"\n",
    "# gen = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "# gen = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "# gen = \"TinyLlama/TinyLlama_v1.1_math_code\"\n",
    "# gen = \"TinyLlama/TinyLlama_v1.1\"\n",
    "# gen = \"google/gemma-2b-it\"\n",
    "# gen = \"google/gemma-2-2b-it\"\n",
    "# gen = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# gen = \"meta-llama/Llama-3.2-1B\"\n",
    "# gen = \"Qwen/Qwen2.5-Coder-0.5B-Instruct\"\n",
    "# gen = \"Qwen/Qwen2-0.5B\"\n",
    "# gen = \"keeeeenw/MicroLlama\"\n",
    "# gen = \"keeeeenw/Llama-3.2-1B-Instruct-Open-R1-Distill\"\n",
    "# gen = \"keeeeenw/MicroLlama-Instruct-0.1\"\n",
    "# gen = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "# gen = \"silma-ai/SILMA-Kashif-2B-Instruct-v1.0\"\n",
    "gen = \"mobiuslabsgmbh/DeepSeek-R1-ReDistill-Qwen-1.5B-v1.0\"\n",
    "# gen = \"microsoft/phi-2\"\n",
    "# Initialize the generation engine.\n",
    "gen_llm = sgl.Engine(model_path=gen)\n",
    "# gen_llm = sgl.Engine(model_path=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "sampling_params = {\"temperature\": 0.5, \"top_p\": 0.95}\n",
    "\n",
    "# Define 20 questions/instructions.\n",
    "questions = [\n",
    "    \"Write a short poem about a soldier.\",\n",
    "    \"Summarize the plot of 'To Kill a Mockingbird' in a few sentences.\",\n",
    "    \"Explain the process of photosynthesis in simple terms.\",\n",
    "    \"Describe the importance of cybersecurity in modern society.\",\n",
    "    \"What are the benefits of regular exercise?\",\n",
    "    \"Outline the major causes of climate change.\",\n",
    "    \"Write a brief story about an astronaut on Mars.\",\n",
    "    \"Compare and contrast two different types of renewable energy.\",\n",
    "    \"Describe how a computer works in layman’s terms.\",\n",
    "    \"What is the significance of the scientific method?\",\n",
    "    \"Explain the benefits of meditation for stress relief.\",\n",
    "    \"Write a creative short story involving a mysterious door.\",\n",
    "    \"Discuss the impact of social media on communication.\",\n",
    "    \"Explain how the stock market works in simple language.\",\n",
    "    \"Describe the importance of voting in a democracy.\",\n",
    "    \"Write a motivational message for someone facing challenges.\",\n",
    "    \"Summarize the rules of chess.\",\n",
    "    \"Explain what makes a good leader.\",\n",
    "    \"Outline the steps required to start a small business.\",\n",
    "    \"Discuss the ethical considerations of artificial intelligence.\"\n",
    "]\n",
    "\n",
    "responses = []\n",
    "\n",
    "# Generate and store responses.\n",
    "for question in questions:\n",
    "    response = gen_llm.generate(question, sampling_params, stream=False)\n",
    "    answer = response.get('text', '').strip()\n",
    "    responses.append({\n",
    "        \"instruction\": question,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "    print(f\"Processed: {question}\")\n",
    "\n",
    "# Save the generated responses to a JSON file.\n",
    "with open(f\"genSILMA-Kashif-2B-Instruct-v1.0.json\", \"w\") as f:\n",
    "    json.dump(responses, f, indent=4)\n",
    "\n",
    "print(\"Generation complete. Responses stored in generation_responses.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea85537",
   "metadata": {},
   "source": [
    "## Normal Evaluation with simple  tranformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd0ff2-29b5-410b-997f-dd4d6e5e39bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Define the model\n",
    "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Load tokenizer and model onto the same device\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Sampling parameters\n",
    "sampling_params = {\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"max_length\": 300,\n",
    "    \"do_sample\": True  # Enable sampling for diversity in responses\n",
    "}\n",
    "\n",
    "# Define 20 questions/instructions.\n",
    "questions = [\n",
    "    \"Write a short poem about a soldier.\",\n",
    "    \"Summarize the plot of 'To Kill a Mockingbird' in a few sentences.\",\n",
    "    \"Explain the process of photosynthesis in simple terms.\",\n",
    "    \"Describe the importance of cybersecurity in modern society.\",\n",
    "    \"What are the benefits of regular exercise?\",\n",
    "    \"Outline the major causes of climate change.\",\n",
    "    \"Write a brief story about an astronaut on Mars.\",\n",
    "    \"Compare and contrast two different types of renewable energy.\",\n",
    "    \"Describe how a computer works in layman’s terms.\",\n",
    "    \"What is the significance of the scientific method?\",\n",
    "    \"Explain the benefits of meditation for stress relief.\",\n",
    "    \"Write a creative short story involving a mysterious door.\",\n",
    "    \"Discuss the impact of social media on communication.\",\n",
    "    \"Explain how the stock market works in simple language.\",\n",
    "    \"Describe the importance of voting in a democracy.\",\n",
    "    \"Write a motivational message for someone facing challenges.\",\n",
    "    \"Summarize the rules of chess.\",\n",
    "    \"Explain what makes a good leader.\",\n",
    "    \"Outline the steps required to start a small business.\",\n",
    "    \"Discuss the ethical considerations of artificial intelligence.\"\n",
    "]\n",
    "\n",
    "responses = []\n",
    "\n",
    "# Generate and store responses.\n",
    "for question in questions:\n",
    "    # Tokenize input and move to the correct device\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate response\n",
    "    output = model.generate(\n",
    "        **inputs, \n",
    "        temperature=sampling_params[\"temperature\"],\n",
    "        top_p=sampling_params[\"top_p\"],\n",
    "        max_length=sampling_params[\"max_length\"],\n",
    "        do_sample=sampling_params[\"do_sample\"]\n",
    "    )\n",
    "\n",
    "    # Decode generated text\n",
    "    response_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    responses.append({\n",
    "        \"instruction\": question,\n",
    "        \"answer\": response_text.strip()\n",
    "    })\n",
    "\n",
    "    print(f\"Processed: {question}\")\n",
    "\n",
    "# Save the generated responses to a JSON file.\n",
    "with open(\"genPhi-3.5-mini-instruct.json\", \"w\") as f:\n",
    "    json.dump(responses, f, indent=4)\n",
    "\n",
    "print(\"Generation complete. Responses stored in genPhi-3.5-mini-instruct.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
