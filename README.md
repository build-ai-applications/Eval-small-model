# ğŸš€ Model Evaluation with SGLang  

This repository contains tools for setting up **SGLang** with **CUDA support** and evaluating various **language models** using a standardized benchmarking approach.  

## ğŸ“‚ Repository Structure  
```
.
â”œâ”€â”€ ğŸ“œ README.md  
â”œâ”€â”€ ğŸ““ Sglang_instruct_eval.ipynb    # Main benchmarking notebook  
â”œâ”€â”€ ğŸ“ Sample Generation/            # Contains model evaluation scores  
â””â”€â”€ ğŸ“„ instruct Benchmark.txt        # Detailed benchmark outputs  
```

## âœ… Prerequisites  
- ğŸ® **NVIDIA GPU** with CUDA support  
- ğŸ **Python 3.10** or later  
- ğŸ–¥ï¸ **Linux** operating system  
- ğŸ’¾ **Sufficient disk space** (~5GB for CUDA, ~2GB for PyTorch, ~1GB for SGLang)  

## âš™ï¸ Setup Instructions  

### ğŸ”¹ 1. CUDA Installation  
```bash
# ğŸš€ Download CUDA 12.1  
wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run

# ğŸ› ï¸ Install CUDA (without driver)  
sudo sh cuda_12.1.0_530.30.02_linux.run

# ğŸ”— Add CUDA to PATH and LD_LIBRARY_PATH  
export PATH=/usr/local/cuda-12.1/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

# ğŸ”„ Make the PATH changes permanent  
echo 'export PATH=/usr/local/cuda-12.1/bin${PATH:+:${PATH}}' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> ~/.bashrc
source ~/.bashrc
```

### ğŸ”¹ 2. PyTorch Installation  
```bash
# âš¡ Install PyTorch with CUDA 12.1 support  
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### ğŸ”¹ 3. SGLang Installation  
```bash
# ğŸ› ï¸ Install SGLang with all dependencies  
pip install "sglang[all]"

# ğŸš€ Install FlashInfer (optional, for better performance)  
pip install flashinfer -i https://flashinfer.ai/whl/cu124/torch2.4/
```

## ğŸ“Š Model Benchmarking  

### ğŸ“Œ Overview  
The repository includes a **comprehensive benchmarking system** that evaluates language models across **20 diverse questions**. The evaluation process includes:  
âœ… **Automated model response generation**  
âœ… **Response quality assessment**  
âœ… **Score aggregation and analysis**  

### â–¶ï¸ Running the Benchmark  
1ï¸âƒ£ Open `Sglang_instruct_eval.ipynb` in **Jupyter Notebook/Lab**  
2ï¸âƒ£ Follow the notebook cells to:  
   - ğŸ”„ Load and initialize models  
   - âœï¸ Generate responses to benchmark questions  
   - ğŸ’¾ Save results in **JSON format**  

### ğŸ† Evaluation Methods  
The framework supports **two evaluation approaches**:  

1ï¸âƒ£ **Automated Evaluation** ğŸ¤–  
   - Uses **larger models (ChatGPT/Claude) as evaluators**  
   - Systematic scoring based on predefined criteria  

2ï¸âƒ£ **Manual Evaluation** ğŸ‘¨â€ğŸ’»  
   - Direct **human assessment** of responses  
   - Qualitative and quantitative scoring  

### ğŸ“‚ Output Format  
Results are stored in **two locations**:  
- ğŸ“ `Sample Generation/` â†’ Contains individual model scores  
- ğŸ“„ `instruct Benchmark.txt` â†’ Detailed benchmark outputs  

## âœ… Verification Steps  
```bash
# ğŸ® Verify CUDA installation  
nvcc --version  

# ğŸ” Verify PyTorch CUDA support  
python3 -c "import torch; print('CUDA available:', torch.cuda.is_available())"

# ğŸ› ï¸ Test SGLang  
python3 -c "import sglang as sgl"
```

## ğŸš€ Quick Start Example  
```python
import sglang as sgl
import asyncio

# ğŸ§  Initialize the engine with a model  
llm = sgl.Engine(model_path="NousResearch/Hermes-3-Llama-3.2-3B")
```

## âš ï¸ Important Notes  
âš¡ Make sure you have the appropriate **NVIDIA drivers installed** before CUDA installation  
âš¡ The CUDA installer will **warn about driver installation** â€“ you can ignore this if you already have compatible drivers  
âš¡ If you encounter **permission issues**, you might need to use `sudo` for some commands  
âš¡ For production use, consider using a **virtual environment**  
âš¡ Benchmark results may **vary** based on model versions and evaluation criteria  

## ğŸ› ï¸ Troubleshooting  
If you encounter any issues:  
ğŸ”¹ Verify your **NVIDIA drivers** are properly installed  
ğŸ”¹ Check if **CUDA paths** are correctly set in your environment  
ğŸ”¹ Ensure your **Python version** is compatible  
ğŸ”¹ Make sure you have **sufficient disk space**  
ğŸ”¹ Check **JSON output format** if evaluation results arenâ€™t being saved properly  

## ğŸ¤ Contributing  
Feel free to contribute by:  
ğŸ”¹ **Adding new benchmark questions**  
ğŸ”¹ **Implementing additional evaluation metrics**  
ğŸ”¹ **Testing with different models**  
ğŸ”¹ **Improving documentation**  

## ğŸ“š References  
ğŸ”— [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)  
ğŸ”— [PyTorch Installation](https://pytorch.org/get-started/locally/)  
ğŸ”— [SGLang Documentation](https://github.com/build-ai-applications/sglang)  
ğŸ”— [FlashInfer](https://flashinfer.ai)  

## ğŸ“œ License  
ğŸ“„ This setup guide and benchmarking framework is provided under the **Apache 2.0**.  
